{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import parselmouth\n",
    "from scipy.signal import find_peaks\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load an audio file\n",
    "def load_audio(file_path):\n",
    "    audio, sample_rate = librosa.load(file_path)\n",
    "    return audio, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_directory = 'tess_database/dataverse_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prosodic feature set extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract pitch\n",
    "def extract_pitch(y, sr):\n",
    "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)\n",
    "    pitch = []\n",
    "    for t in range(pitches.shape[1]):\n",
    "        index = magnitudes[:, t].argmax()\n",
    "        pitch.append(pitches[index, t])\n",
    "    pitch = np.trim_zeros(np.array(pitch))\n",
    "    return np.mean(pitch), np.std(pitch)  # Returning mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract energy\n",
    "def extract_energy(y):\n",
    "    frame_length = 1024\n",
    "    energy = np.array([\n",
    "        np.sum(np.abs(y[i:i+frame_length]**2))\n",
    "        for i in range(0, len(y), frame_length)\n",
    "    ])\n",
    "    return np.mean(energy), np.std(energy)  # Returning mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract duration features\n",
    "def extract_duration_features(y, sr):\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    tempogram = librosa.feature.tempogram(y=y, sr=sr)\n",
    "    speech_rate = np.mean(tempogram)  # Approximation for speech rate\n",
    "    return duration, speech_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract silence duration\n",
    "def extract_silence_duration(y, sr, threshold=0.02):\n",
    "    y_abs = np.abs(y)\n",
    "    silence_duration = np.sum(y_abs < threshold) / sr\n",
    "    return silence_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate voiced vs. unvoiced speech duration\n",
    "def voiced_unvoiced(y, sr, hop_length=512):\n",
    "    # Using zero-crossing rate to estimate voiced and unvoiced segments\n",
    "    zero_crossings = librosa.feature.zero_crossing_rate(y, frame_length=hop_length, hop_length=hop_length)\n",
    "    voiced = np.sum(zero_crossings > 0.1) * hop_length / sr  # Threshold for voiced segments\n",
    "    unvoiced = np.sum(zero_crossings <= 0.1) * hop_length / sr  # Threshold for unvoiced segments\n",
    "    return voiced, unvoiced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract pitch variation\n",
    "def extract_pitch_variation(y, sr):\n",
    "    pitches, _ = librosa.core.piptrack(y=y, sr=sr)\n",
    "    pitch_variation = np.var(pitches)\n",
    "    return pitch_variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to extract all features\n",
    "def extract_prosodic_features(file_path):\n",
    "    y, sr = load_audio(file_path)\n",
    "    mean_pitch, std_pitch = extract_pitch(y, sr)\n",
    "    mean_energy, std_energy = extract_energy(y)\n",
    "    duration, speech_rate = extract_duration_features(y, sr)\n",
    "    silence_duration = extract_silence_duration(y, sr)\n",
    "    voiced_duration, unvoiced_duration = voiced_unvoiced(y, sr)\n",
    "    pitch_variation = extract_pitch_variation(y, sr)\n",
    "    \n",
    "    features = {\n",
    "        'mean_pitch': mean_pitch,\n",
    "        'std_pitch': std_pitch,\n",
    "        'mean_energy': mean_energy,\n",
    "        'std_energy': std_energy,\n",
    "        'duration': duration,\n",
    "        'speech_rate': speech_rate,\n",
    "        'silence_duration': silence_duration,\n",
    "        'voiced_duration': voiced_duration,\n",
    "        'unvoiced_duration': unvoiced_duration,\n",
    "        'pitch_variation': pitch_variation\n",
    "    }\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_pitch    std_pitch  mean_energy  std_energy  duration  speech_rate  \\\n",
      "0   449.610199   381.894135     9.676556   11.913024  2.075601     0.064879   \n",
      "1  1007.365051  1288.699097     0.327053    0.572303  2.345760     0.097476   \n",
      "2   792.386292  1063.287964     0.588500    0.856471  1.794921     0.059025   \n",
      "3   708.017578  1036.089600     0.109407    0.107576  1.861633     0.159514   \n",
      "4   516.532471   480.635956     4.721364    6.218035  1.650204     0.054590   \n",
      "\n",
      "   silence_duration  voiced_duration  unvoiced_duration  pitch_variation  \\\n",
      "0          0.940317         0.696599           1.393197     17896.482422   \n",
      "1          1.993787         0.882358           1.486077     47069.945312   \n",
      "2          1.316961         0.255420           1.555737     13634.870117   \n",
      "3          1.706621         0.487619           1.393197     12398.823242   \n",
      "4          0.870113         0.673379           0.998458     52227.867188   \n",
      "\n",
      "               filename  \n",
      "0    YAF_wire_happy.wav  \n",
      "1   OAF_fat_disgust.wav  \n",
      "2  OAF_bought_happy.wav  \n",
      "3   OAF_fit_neutral.wav  \n",
      "4     YAF_dead_fear.wav  \n",
      "Features extracted and saved to features/prosodic_features_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store feature data\n",
    "data = []\n",
    "\n",
    "# Iterate over files in the EmoDB directory\n",
    "for filename in os.listdir(db_directory):\n",
    "    if filename.endswith(\".wav\"):  # Assuming the files are in WAV format\n",
    "        file_path = os.path.join(db_directory, filename)\n",
    "        # Extract features from the audio file\n",
    "        features = extract_prosodic_features(file_path)  # Your feature extraction function\n",
    "        # Include the filename or other identifiers as needed\n",
    "        features['filename'] = filename\n",
    "        # Append the features to the data list\n",
    "        data.append(features)\n",
    "\n",
    "# Convert the list of feature dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "print(df.head())\n",
    "\n",
    "# Define the path for the output CSV file\n",
    "output_csv_path = 'features/prosodic_features_test.csv'\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f'Features extracted and saved to {output_csv_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Acoustic feature set extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract MFCC features\n",
    "def extract_mfcc(audio, sample_rate, n_mfcc=13):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfccs.T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract LPCC features\n",
    "def extract_lpcc(audio, sample_rate, n_lpcc=13):\n",
    "    lpccs = librosa.lpc(y=audio, order=n_lpcc)\n",
    "    return lpccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract LFPC features\n",
    "def extract_lfpc(audio, sample_rate, n_bands=40):\n",
    "    stft = np.abs(librosa.stft(audio))\n",
    "    lfpcs = librosa.feature.melspectrogram(S=stft**2, sr=sample_rate, n_mels=n_bands)\n",
    "    return np.mean(lfpcs.T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract GFCC features\n",
    "def extract_gfcc(audio, sample_rate, n_gfcc=13):\n",
    "    gfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_gfcc, htk=True)\n",
    "    return np.mean(gfccs.T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract formants\n",
    "def extract_formants(audio, sample_rate):\n",
    "    pitches, magnitudes = librosa.core.piptrack(y=audio, sr=sample_rate)\n",
    "    formants = np.max(magnitudes, axis=0)\n",
    "    return formants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to extract all features\n",
    "def extract_acoustic_features(file_path):\n",
    "    audio, sample_rate = load_audio(file_path)\n",
    "    features = {}\n",
    "    features['mfcc'] = extract_mfcc(audio, sample_rate)\n",
    "    features['lpcc'] = extract_lpcc(audio, sample_rate)\n",
    "    features['lfpc'] = extract_lfpc(audio, sample_rate)\n",
    "    features['gfcc'] = extract_gfcc(audio, sample_rate)\n",
    "    features['formants'] = extract_formants(audio, sample_rate)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                mfcc  \\\n",
      "0  [-300.5379, 40.605106, -28.108757, 17.45625, -...   \n",
      "1  [-426.9512, 71.14616, 3.221315, -10.768615, 13...   \n",
      "2  [-441.6265, 92.82772, 19.227163, -14.2388115, ...   \n",
      "3  [-515.32117, 59.07907, 16.712137, 10.546044, 1...   \n",
      "4  [-295.1762, 41.771236, -15.355103, 15.900852, ...   \n",
      "\n",
      "                                                lpcc  \\\n",
      "0  [1.0, -1.7448161, 1.0000771, 0.1465317, -0.435...   \n",
      "1  [1.0, -0.8589723, -0.024427855, -0.314105, -0....   \n",
      "2  [1.0, -0.9826942, -0.07148894, -0.59121585, 0....   \n",
      "3  [1.0, -1.0153912, 0.19047754, -0.6288274, 0.62...   \n",
      "4  [1.0, -1.2599481, 0.16007785, 0.21459147, 0.06...   \n",
      "\n",
      "                                                lfpc  \\\n",
      "0  [0.0023599719, 0.49987122, 2.4315553, 2.492736...   \n",
      "1  [0.0057541984, 0.15236326, 0.28910416, 0.20294...   \n",
      "2  [0.092098996, 0.15914197, 0.42431548, 0.923114...   \n",
      "3  [0.0030326215, 0.14114383, 0.04965497, 0.30300...   \n",
      "4  [0.049695488, 0.19012822, 1.384158, 6.0009294,...   \n",
      "\n",
      "                                                gfcc  \\\n",
      "0  [-304.4626, 42.422913, -36.75225, 6.0808425, -...   \n",
      "1  [-429.4786, 72.63952, 5.5388756, -17.278942, 2...   \n",
      "2  [-444.72406, 93.188446, 19.440857, -20.035042,...   \n",
      "3  [-512.48193, 64.98895, 17.461441, 3.29748, 6.6...   \n",
      "4  [-297.13403, 44.648605, -19.45785, 6.7212124, ...   \n",
      "\n",
      "                                            formants              filename  \n",
      "0  [0.03966941, 0.058787834, 0.0, 0.0, 0.0, 0.0, ...    YAF_wire_happy.wav  \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.22354135, 0.28725365, 0...   OAF_fat_disgust.wav  \n",
      "2  [0.06723964, 0.15602028, 0.15748529, 0.0, 0.17...  OAF_bought_happy.wav  \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14064659, 0.1...   OAF_fit_neutral.wav  \n",
      "4  [0.1433569, 0.63239914, 0.91603905, 0.52246165...     YAF_dead_fear.wav  \n",
      "Features extracted and saved to features/acoustic_features_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store feature data\n",
    "data = []\n",
    "\n",
    "# Iterate over files in the EmoDB directory\n",
    "for filename in os.listdir(db_directory):\n",
    "    if filename.endswith(\".wav\"):  # Assuming the files are in WAV format\n",
    "        file_path = os.path.join(db_directory, filename)\n",
    "        # Extract features from the audio file\n",
    "        features = extract_acoustic_features(file_path)  # Your feature extraction function\n",
    "        # Include the filename or other identifiers as needed\n",
    "        features['filename'] = filename\n",
    "        # Append the features to the data list\n",
    "        data.append(features)\n",
    "\n",
    "# Convert the list of feature dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "print(df.head())\n",
    "\n",
    "# Define the path for the output CSV file\n",
    "output_csv_path = 'features/acoustic_features_test.csv'\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f'Features extracted and saved to {output_csv_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
